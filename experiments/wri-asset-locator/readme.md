# WRI Asset locator

Fetches information about various WRI assets (currently datasets) and displays them visually in a 2d projection for a user to search and explore. 

## Idea garden reference

This experiment has an Asana entry: 
https://app.asana.com/1/25496124013636/project/1210050417738685/task/1211762347149448?focus=true

Originating idea from Evan:
Asana: https://app.asana.com/1/25496124013636/project/1210050417738685/task/1210826187134586?focus=true

## Purpose

**Purpose: Provide a simple way for user to find relevant datasets and link to where it can be viewed/downloaded.**

Compare to the WRI Dataset Explorer -- this is more lightweight, more inclusive of assets. Provides only basic information about the selected asset, and a link. 


## Approach

There is documentation built into the main notebook
`wri_dataset_locator_combined.py`

Experiment Methodology Steps: 
* Fetches a list of assets and metadata from various sources, such as ResourceWatch. 
* Flattens all descriptions and information into a text string per asset. 
* Embeds the text string in a high-dimensional space using a transformer, then back down to a 2-dim space. 
* Enable a search query which is embedded with the same transfomer, can compute distances to each asset
* Create a simple UI and visualization


### List of files

The main notebook: `wri_dataset_locator_combined.py`
* This is the main notebook for the experiment
* requires CSVs generated by other notebooks
* Combines data from all the CSVs and does the rest of the work

There is one notebook per source, each writes out a CSV file. 
- `fetch_datasets_arcgis_wri_catalog.py` : fetch datasets from the ARCGIS catalog
- `fetch_datasets_global_forest_watch.py` : fetch datasets from Global Forest Watch API
- `fetch_datasets_resource_watch_datasets.py` : fetch datasets from the Resource Watch API
- `fetch_datasets_scrape_pdfreport_energy_access_explorer.py` : fetch dataset info about EAE from the methodology report
- `fetch_datasets_wri_data_explorer.py` : fetch datasets from the WRI Data Explorer

## How to run the experiment

Pre-requisites
* `uv` must be installed. 
* other dependencies are handled by `uv`

Note on GPUs
* embedding is done locally. This takes some computation. 
* GPU(s) used if available
* If no GPU is available, the the CPU(s) will be used. This may be slow (~10 minutes for 650 assets)
* Some caching is utilized with marimo's persistent cache feature

Setup (one time only) : 
* clone the repository and navigate to this experiment's folder
* Running for the first time: 
    * Run each of the "Fetch" notebooks, in any order
    * Then run the main notebook

Subsequent runs
* The fetch notebooks do not need to be run again. 
* The main notebook will attempt some caching

To run a notebook: 
```
uvx marimo edit --sandbox <name of file.py>
```
This command will open a browser window to a **marimo** notebook, which provides an interface to the experiment as well as the code itself. 

